{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Keras has the MNIST digits as a built in dataset. Note that this requires an internet connection as the data is downloaded and not directly in the Keras package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "digits = mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images, in greyscale, are really just bytes running 0-255. Which is convenient, since Keras needs every bit of data to be\n",
    "numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 3 18 18 18 126 136 175 26 166 255 247 127 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 30 36 94 154 170 253 253 253 253 253 225 172 253 242 195 64 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 49 238 253 253 253 253 253 253 253 253 251 93 82 82 56 39 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 18 219 253 253 253 253 253 198 182 247 241 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 80 156 107 253 253 205 11 0 43 154 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 14 1 154 253 90 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 139 253 190 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 11 190 253 70 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 35 241 225 160 108 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 81 240 253 253 119 25 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 45 186 253 253 150 27 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 16 93 252 253 187 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 249 253 249 64 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 46 130 183 253 253 207 2 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 39 148 229 253 253 253 250 182 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 24 114 221 253 253 253 253 201 78 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 23 66 213 253 253 253 253 198 81 2 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 18 171 219 253 253 253 253 195 80 9 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 55 172 226 253 253 253 253 244 133 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 136 253 253 253 212 135 132 16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(linewidth=90, formatter={'all': lambda x: '{0}'.format(x)})\n",
    "for row in train_images[0]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's actually see this as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f543fe1ca20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wPNNnTglMuB0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f543fed1ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[1], cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty standard, it's an array, with an array of arrays, each holding the pixel. Believe it or not, you now know tensors. Let's look at the shape of the data. It's a 3D array -- image, X, Y, with the values in the array just being 0-255 8 bit integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras algorithms have a data trick - they work on floating point math, and they work best when that data ranges from 0.0 to 1.0. So you always need to normalize your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "(train_images[0] / train_images.max())[5:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So -- that's input -- images are just multidimensional arrays, and you need to remember to normalize them into floating point ranging 0.0 to 1.0. Now for outputs, the images are 0-9 digits and each of these digits is a 'class', not in the OO sense, but in the classification sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our rules above about ranging numbers from 0.0 to 1.0 also apply to the outputs of Keras. So, we have to transform labels, but -- we want them discreet, we want to predict 0 1 2 3 4 5 6 7 8 9 -- predicting 1.5 isn't a digit. So -- we will do a categorical 'one-hot' encoding, which you can think of as a kind of bitmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.to_categorical(train_labels, 10)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(keras.utils.to_categorical(train_labels, 10)[:10], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[4], cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it -- Keras machine learning is going to learn a function that takes a bitmap, and returns another bitmap, which just so happens to be encoded into floating point multidemsional arrays, known as tensors.\n",
    "\n",
    "This really is the cookbook:\n",
    "  * Tensors are just multidimensional arrays\n",
    "  * Set them up as (image, x, y), with the pixels being 0.0 to 1.0\n",
    "  * Labels or Classes are just array\n",
    "  * Set them up as (image, number of classes)\n",
    "  * Use one-hot encoding -- set the target label to 1.0, others to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
